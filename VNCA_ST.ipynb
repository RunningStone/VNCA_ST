{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')\n",
    "\n",
    "import VNCA_ST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VNCA_ST.Model.VNCA import VNCA, VNCA_paras\n",
    "\n",
    "paras = VNCA_paras()\n",
    "paras.h = 32\n",
    "paras.w = 32\n",
    "paras.n_channels = 3\n",
    "paras.z_size = 256\n",
    "paras.p_update = 1.0\n",
    "paras.dmg_size = 16\n",
    "paras.min_steps =64\n",
    "paras.max_steps = 128\n",
    "\n",
    "paras.batch_size =32\n",
    "\n",
    "# update net\n",
    "paras.nca_hid = 128\n",
    "paras.n_mixtures = 1\n",
    "\n",
    "\n",
    "\n",
    "# encoder net\n",
    "paras.filter_size = 5\n",
    "paras.pad = paras.filter_size // 2\n",
    "paras.encoder_hid = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from VNCA_ST.Model.base import Residual\n",
    "from VNCA_ST.Model.distribution import DiscretizedMixtureLogitsDistribution\n",
    "\n",
    "n_mixtures = paras.n_mixtures # 转为常量\n",
    "def state_to_dist(state):\n",
    "    return DiscretizedMixtureLogitsDistribution(n_mixtures, state[:, :n_mixtures * 10, :, :])\n",
    "\n",
    "def create_encoder(paras):\n",
    "    encoder = nn.Sequential(\n",
    "        nn.Conv2d(paras.n_channels, paras.encoder_hid * 2 ** 0, paras.filter_size, padding=paras.pad), nn.ELU(),  # (bs, 32, h, w)\n",
    "        nn.Conv2d(paras.encoder_hid * 2 ** 0, paras.encoder_hid * 2 ** 1, paras.filter_size, padding=paras.pad, stride=2), nn.ELU(),  # (bs, 64, h//2, w//2)\n",
    "        nn.Conv2d(paras.encoder_hid * 2 ** 1, paras.encoder_hid * 2 ** 2, paras.filter_size, padding=paras.pad, stride=2), nn.ELU(),  # (bs, 128, h//4, w//4)\n",
    "        nn.Conv2d(paras.encoder_hid * 2 ** 2, paras.encoder_hid * 2 ** 3, paras.filter_size, padding=paras.pad, stride=2), nn.ELU(),  # (bs, 256, h//8, w//8)\n",
    "        nn.Conv2d(paras.encoder_hid * 2 ** 3, paras.encoder_hid * 2 ** 4, paras.filter_size, padding=paras.pad, stride=2), nn.ELU(),  # (bs, 512, h//16, w//16),\n",
    "        nn.Flatten(),  # (bs, 512*h//16*w//16)\n",
    "        nn.Linear(paras.encoder_hid * (2 ** 4) * paras.h // 16 * paras.w // 16, 2 * paras.z_size),\n",
    "    )\n",
    "    return encoder\n",
    "\n",
    "def create_updateNet(paras):\n",
    "    update_net = nn.Sequential(\n",
    "        nn.Conv2d(paras.z_size, paras.nca_hid, 3, padding=1),\n",
    "        Residual(\n",
    "            nn.Conv2d(paras.nca_hid, paras.nca_hid, 1),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(paras.nca_hid, paras.nca_hid, 1),\n",
    "        ),\n",
    "        Residual(\n",
    "            nn.Conv2d(paras.nca_hid, paras.nca_hid, 1),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(paras.nca_hid, paras.nca_hid, 1),\n",
    "        ),\n",
    "        Residual(\n",
    "            nn.Conv2d(paras.nca_hid, paras.nca_hid, 1),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(paras.nca_hid, paras.nca_hid, 1),\n",
    "        ),\n",
    "        Residual(\n",
    "            nn.Conv2d(paras.nca_hid, paras.nca_hid, 1),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(paras.nca_hid, paras.nca_hid, 1),\n",
    "        ),\n",
    "        nn.Conv2d(paras.nca_hid, paras.z_size, 1)\n",
    "    )\n",
    "    update_net[-1].weight.data.fill_(0.0)\n",
    "    update_net[-1].bias.data.fill_(0.0)\n",
    "    return update_net\n",
    "\n",
    "\n",
    "encoder = create_encoder(paras)\n",
    "update_net = create_updateNet(paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The daily quota of the file img_align_celeba.zip is exceeded and it can't be downloaded. This is a limitation of Google Drive and can only be overcome by trying again later.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/shi/WorkSpace/projects/scLLM_workspace/data/test/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m tp \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([transforms\u001b[38;5;241m.\u001b[39mResize((paras\u001b[38;5;241m.\u001b[39mh, paras\u001b[38;5;241m.\u001b[39mw)), transforms\u001b[38;5;241m.\u001b[39mToTensor()])\n\u001b[0;32m----> 6\u001b[0m train_data, val_data, test_data \u001b[38;5;241m=\u001b[39m [datasets\u001b[38;5;241m.\u001b[39mCelebA(data_dir, \n\u001b[1;32m      7\u001b[0m                                                    split\u001b[38;5;241m=\u001b[39msplit, \n\u001b[1;32m      8\u001b[0m                                                    download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m      9\u001b[0m                                                    transform\u001b[38;5;241m=\u001b[39mtp) \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/shi/WorkSpace/projects/scLLM_workspace/data/test/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m tp \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([transforms\u001b[38;5;241m.\u001b[39mResize((paras\u001b[38;5;241m.\u001b[39mh, paras\u001b[38;5;241m.\u001b[39mw)), transforms\u001b[38;5;241m.\u001b[39mToTensor()])\n\u001b[0;32m----> 6\u001b[0m train_data, val_data, test_data \u001b[38;5;241m=\u001b[39m [\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCelebA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[0;32m~/anaconda3/envs/VCNA_ST/lib/python3.9/site-packages/torchvision/datasets/celeba.py:80\u001b[0m, in \u001b[0;36mCelebA.__init__\u001b[0;34m(self, root, split, target_type, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_transform is specified but target_type is empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity():\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/VCNA_ST/lib/python3.9/site-packages/torchvision/datasets/celeba.py:150\u001b[0m, in \u001b[0;36mCelebA.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (file_id, md5, filename) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_list:\n\u001b[0;32m--> 150\u001b[0m     \u001b[43mdownload_file_from_google_drive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_folder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m extract_archive(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_folder, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg_align_celeba.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/VCNA_ST/lib/python3.9/site-packages/torchvision/datasets/utils.py:246\u001b[0m, in \u001b[0;36mdownload_file_from_google_drive\u001b[0;34m(file_id, root, filename, md5)\u001b[0m\n\u001b[1;32m    243\u001b[0m         api_response, content \u001b[38;5;241m=\u001b[39m _extract_gdrive_api_response(response)\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m api_response \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuota exceeded\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 246\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe daily quota of the file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is exceeded and it \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be downloaded. This is a limitation of Google Drive \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand can only be overcome by trying again later.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m         )\n\u001b[1;32m    252\u001b[0m     _save_response_content(content, fpath)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# In case we deal with an unhandled GDrive API response, the file should be smaller than 10kB and contain only text\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The daily quota of the file img_align_celeba.zip is exceeded and it can't be downloaded. This is a limitation of Google Drive and can only be overcome by trying again later."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "data_dir = \"/home/shi/WorkSpace/projects/scLLM_workspace/data/test/\"\n",
    "tp = transforms.Compose([transforms.Resize((paras.h, paras.w)), transforms.ToTensor()])\n",
    "train_data, val_data, test_data = [datasets.CelebA(data_dir, \n",
    "                                                   split=split, \n",
    "                                                   download=True, \n",
    "                                                   transform=tp) for split in [\"train\", \"valid\", \"test\"]]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
